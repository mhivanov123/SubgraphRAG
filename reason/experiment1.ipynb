{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f822c7cd-73d1-4176-9ea4-7e363915165e",
   "metadata": {},
   "source": [
    "IDEA:\n",
    "1. Use the POG subobjective idea to split up the question into smaller questions\n",
    "2. Use SubgraphRAG for each of these smaller subobjectives, allowing us to fit smaller context into each prompt step\n",
    "3. Combine Each subobjective response into one coherent answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a42b54-1a69-4990-81b9-806d52490184",
   "metadata": {},
   "source": [
    "Below, we create a custom RetrieverDataset class that deals with individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "343369d8-a950-47ce-aeac-1b0da03ec4f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class customRetrieverDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample,\n",
    "        emb_dict,\n",
    "        skip_no_path=True\n",
    "    ):\n",
    "\n",
    "        # Extract directed shortest paths from topic entities to answer\n",
    "        # entities or vice versa as weak supervision signals for triple scoring.\n",
    "        triple_score_dict = self._get_triple_scores(\n",
    "            sample)\n",
    "\n",
    "        # Put everything together.\n",
    "        self._assembly(\n",
    "            sample, triple_score_dict, emb_dict, skip_no_path)\n",
    "\n",
    "    def _load_processed(\n",
    "        self,\n",
    "        dataset_name,\n",
    "        split\n",
    "    ):\n",
    "        processed_file = os.path.join(\n",
    "            f'data_files/{dataset_name}/processed/{split}.pkl')\n",
    "        with open(processed_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def _get_triple_scores(\n",
    "        self,\n",
    "        sample\n",
    "    ):\n",
    "        \n",
    "        #sample_i = processed_dict_list[i]\n",
    "        #sample_i_id = sample_i['id']\n",
    "        triple_scores, max_path_length = self._extract_paths_and_score(\n",
    "            sample)\n",
    "        \n",
    "        triple_score_dict = {\n",
    "            'triple_scores': triple_scores,\n",
    "            'max_path_length': max_path_length\n",
    "        }\n",
    "        \n",
    "        return triple_score_dict\n",
    "\n",
    "    def _extract_paths_and_score(\n",
    "        self,\n",
    "        sample\n",
    "    ):\n",
    "        nx_g = self._get_nx_g(\n",
    "            sample['h_id_list'],\n",
    "            sample['r_id_list'],\n",
    "            sample['t_id_list']\n",
    "        )\n",
    "\n",
    "        # Each raw path is a list of entity IDs.\n",
    "        path_list_ = []\n",
    "        for q_entity_id in sample['q_entity_id_list']:\n",
    "            for a_entity_id in sample['a_entity_id_list']:\n",
    "                paths_q_a = self._shortest_path(nx_g, q_entity_id, a_entity_id)\n",
    "                if len(paths_q_a) > 0:\n",
    "                    path_list_.extend(paths_q_a)\n",
    "\n",
    "        if len(path_list_) == 0:\n",
    "            max_path_length = None\n",
    "        else:\n",
    "            max_path_length = 0\n",
    "\n",
    "        # Each processed path is a list of triple IDs.\n",
    "        path_list = []\n",
    "\n",
    "        for path in path_list_:\n",
    "            num_triples_path = len(path) - 1\n",
    "            max_path_length = max(max_path_length, num_triples_path)\n",
    "            triples_path = []\n",
    "\n",
    "            for i in range(num_triples_path):\n",
    "                h_id_i = path[i]\n",
    "                t_id_i = path[i+1]\n",
    "                triple_id_i_list = [\n",
    "                    nx_g[h_id_i][t_id_i]['triple_id']\n",
    "                ]              \n",
    "                triples_path.append(triple_id_i_list)\n",
    "\n",
    "            path_list.append(triples_path)\n",
    "\n",
    "        num_triples = len(sample['h_id_list'])\n",
    "        triple_scores = self._score_triples(\n",
    "            path_list,\n",
    "            num_triples\n",
    "        )\n",
    "        \n",
    "        return triple_scores, max_path_length\n",
    "\n",
    "    def _get_nx_g(\n",
    "        self,\n",
    "        h_id_list,\n",
    "        r_id_list,\n",
    "        t_id_list\n",
    "    ):\n",
    "        nx_g = nx.DiGraph()\n",
    "        num_triples = len(h_id_list)\n",
    "        for i in range(num_triples):\n",
    "            h_i = h_id_list[i]\n",
    "            r_i = r_id_list[i]\n",
    "            t_i = t_id_list[i]\n",
    "            nx_g.add_edge(h_i, t_i, triple_id=i, relation_id=r_i)\n",
    "\n",
    "        return nx_g\n",
    "\n",
    "    def _shortest_path(\n",
    "        self,\n",
    "        nx_g,\n",
    "        q_entity_id,\n",
    "        a_entity_id\n",
    "    ):\n",
    "        try:\n",
    "            forward_paths = list(nx.all_shortest_paths(nx_g, q_entity_id, a_entity_id))\n",
    "        except:\n",
    "            forward_paths = []\n",
    "        \n",
    "        try:\n",
    "            backward_paths = list(nx.all_shortest_paths(nx_g, a_entity_id, q_entity_id))\n",
    "        except:\n",
    "            backward_paths = []\n",
    "        \n",
    "        full_paths = forward_paths + backward_paths\n",
    "        if (len(forward_paths) == 0) or (len(backward_paths) == 0):\n",
    "            return full_paths\n",
    "        \n",
    "        min_path_len = min([len(path) for path in full_paths])\n",
    "        refined_paths = []\n",
    "        for path in full_paths:\n",
    "            if len(path) == min_path_len:\n",
    "                refined_paths.append(path)\n",
    "        \n",
    "        return refined_paths\n",
    "\n",
    "    def _score_triples(\n",
    "        self,\n",
    "        path_list,\n",
    "        num_triples\n",
    "    ):\n",
    "        triple_scores = torch.zeros(num_triples)\n",
    "        \n",
    "        for path in path_list:\n",
    "            for triple_id_list in path:\n",
    "                triple_scores[triple_id_list] = 1.\n",
    "\n",
    "        return triple_scores\n",
    "\n",
    "    def _load_emb(\n",
    "        self,\n",
    "        dataset_name,\n",
    "        text_encoder_name,\n",
    "        split\n",
    "    ):\n",
    "        file_path = f'data_files/{dataset_name}/emb/{text_encoder_name}/{split}.pth'\n",
    "        dict_file = torch.load(file_path)\n",
    "        \n",
    "        return dict_file\n",
    "\n",
    "    def _assembly(\n",
    "        self,\n",
    "        sample_i,\n",
    "        triple_score_dict,\n",
    "        emb_dict,\n",
    "        skip_no_path,\n",
    "    ):\n",
    "        self.processed_dict_list = []\n",
    "\n",
    "        num_relevant_triples = []\n",
    "        num_skipped = 0\n",
    "        \n",
    "        #sample_i = processed_dict_list[i]\n",
    "        #sample_i_id = sample_i['id']\n",
    "        #assert sample_i_id in triple_score_dict\n",
    "\n",
    "        triple_score_i = triple_score_dict['triple_scores']\n",
    "        max_path_length_i = triple_score_dict['max_path_length']\n",
    "\n",
    "        num_relevant_triples_i = len(triple_score_i.nonzero())\n",
    "        num_relevant_triples.append(num_relevant_triples_i)\n",
    "\n",
    "        sample_i['target_triple_probs'] = triple_score_i\n",
    "        sample_i['max_path_length'] = max_path_length_i\n",
    "\n",
    "        # if skip_no_path and (max_path_length_i in [None, 0]):\n",
    "        #     num_skipped += 1\n",
    "        #     continue\n",
    "\n",
    "        sample_i.update(emb_dict)\n",
    "\n",
    "        sample_i['a_entity'] = list(set(sample_i['a_entity']))\n",
    "        sample_i['a_entity_id_list'] = list(set(sample_i['a_entity_id_list']))\n",
    "\n",
    "        # PE for topic entities.\n",
    "        num_entities_i = len(sample_i['text_entity_list']) + len(sample_i['non_text_entity_list'])\n",
    "        topic_entity_mask = torch.zeros(num_entities_i)\n",
    "        topic_entity_mask[sample_i['q_entity_id_list']] = 1.\n",
    "        topic_entity_one_hot = F.one_hot(topic_entity_mask.long(), num_classes=2)\n",
    "        sample_i['topic_entity_one_hot'] = topic_entity_one_hot.float()\n",
    "\n",
    "        self.processed_dict_list.append(sample_i)\n",
    "        self.processed_dict = sample_i\n",
    "\n",
    "        median_num_relevant = int(np.median(num_relevant_triples))\n",
    "        mean_num_relevant = int(np.mean(num_relevant_triples))\n",
    "        max_num_relevant = int(np.max(num_relevant_triples))\n",
    "\n",
    "        print(f'# skipped samples: {num_skipped}')\n",
    "        print(f'# relevant triples | median: {median_num_relevant} | mean: {mean_num_relevant} | max: {max_num_relevant}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_dict_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.processed_dict_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383b445-ad0d-41d7-a6b6-d9aab63711c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, from the EmbInferDataset, we extract the processed sample, which presents sample info in desired format, and feed it into RetrieverDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e89acd-ca5b-4ce1-9ce6-a2a84353aafc",
   "metadata": {},
   "source": [
    "Next, we load in our retrieval model, that performs convolution and subsequent classification on triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921a0ef-9616-4de8-8838-0c1dfef3488d",
   "metadata": {},
   "source": [
    "Now we have our generated triples along with scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6ce43-efa1-4082-bdff-35960a2de214",
   "metadata": {},
   "source": [
    "EMBEDDING MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dac6eb3-dadd-4d31-8f2b-b6b60e1984f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/mhadjiivanov/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.5.1+cu121 with CUDA 1201 (you have 2.1.0+cu121)\n",
      "    Python  3.10.16 (you have 3.10.16)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "from src.config.emb import load_yaml\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "dataset_name = \"webqsp\"\n",
    "config_file = f'../retrieve/configs/emb/gte-large-en-v1.5/{dataset_name}.yaml'\n",
    "config = load_yaml(config_file)\n",
    "torch.set_num_threads(config['env']['num_threads'])\n",
    "\n",
    "text_encoder_name = config['text_encoder']['name']\n",
    "if text_encoder_name == 'gte-large-en-v1.5':\n",
    "    from src.model.text_encoders import GTELargeEN\n",
    "    text_encoder = GTELargeEN(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02437f99-eaf8-4e69-bbd6-dba3010e53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sample(sample):\n",
    "    id, q_text, text_entity_list, relation_list = sample['id'], sample['question'], sample['text_entity_list'], sample['relation_list']\n",
    "    q_emb, entity_embs, relation_embs = text_encoder(q_text, text_entity_list, relation_list)\n",
    "    emb_dict_i = {\n",
    "    'q_emb': q_emb,\n",
    "    'entity_embs': entity_embs,\n",
    "    'relation_embs': relation_embs\n",
    "    }\n",
    "    return id, emb_dict_i\n",
    "\n",
    "def embed_question(question):\n",
    "    q_emb = text_encoder(q_text)\n",
    "    emb_dict_i = {\n",
    "    'q_emb': q_emb\n",
    "    }\n",
    "    return id, emb_dict_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969e8de-25c6-42b1-8213-d241e0ee5ddc",
   "metadata": {},
   "source": [
    "RETRIEVAL MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeda9a2d-3912-4781-80aa-3df401d637ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Retriever(\n",
       "  (non_text_entity_emb): Embedding(1, 1024)\n",
       "  (dde): DDE(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x PEConv()\n",
       "    )\n",
       "    (reverse_layers): ModuleList(\n",
       "      (0-1): 2 x PEConv()\n",
       "    )\n",
       "  )\n",
       "  (pred): Sequential(\n",
       "    (0): Linear(in_features=4116, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.model.retriever import Retriever\n",
    "from src.setup import set_seed, prepare_sample\n",
    "\n",
    "device = torch.device(f'cuda:0')\n",
    "    \n",
    "cpt = torch.load(\"/home/gridsan/mhadjiivanov/meng/SubgraphRAG/retrieve/webqsp_Jan03-19:20:34/cpt.pth\", map_location='cpu')\n",
    "config = cpt['config']\n",
    "set_seed(config['env']['seed'])\n",
    "torch.set_num_threads(config['env']['num_threads'])\n",
    "\n",
    "emb_size = 1024 #infer_set[0]['q_emb'].shape[-1]\n",
    "model = Retriever(emb_size, **config['retriever']).to(device)\n",
    "model.load_state_dict(cpt['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c98aa4c-c4b2-4339-a7f7-9f1435d74df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.dataset.retriever import collate_retriever\n",
    "from src.setup import set_seed, prepare_sample\n",
    "\n",
    "max_K = 50\n",
    "\n",
    "def get_top_k(raw_sample, max_K):\n",
    "    \n",
    "    pred_dict = dict()\n",
    "\n",
    "    sample = collate_retriever([raw_sample])\n",
    "    h_id_tensor, r_id_tensor, t_id_tensor, q_emb, entity_embs,\\\n",
    "        num_non_text_entities, relation_embs, topic_entity_one_hot,\\\n",
    "        target_triple_probs, a_entity_id_list = prepare_sample(device, sample)\n",
    "    \n",
    "    entity_list = raw_sample['text_entity_list'] + raw_sample['non_text_entity_list']\n",
    "    relation_list = raw_sample['relation_list']\n",
    "    top_K_triples = []\n",
    "    target_relevant_triples = []\n",
    "\n",
    "    if len(h_id_tensor) != 0:\n",
    "        pred_triple_logits = model(\n",
    "            h_id_tensor, r_id_tensor, t_id_tensor, q_emb, entity_embs,\n",
    "            num_non_text_entities, relation_embs, topic_entity_one_hot)\n",
    "        pred_triple_scores = torch.sigmoid(pred_triple_logits).reshape(-1)\n",
    "        top_K_results = torch.topk(pred_triple_scores, \n",
    "                                   min(max_K, len(pred_triple_scores)))\n",
    "        top_K_scores = top_K_results.values.cpu().tolist()\n",
    "        top_K_triple_IDs = top_K_results.indices.cpu().tolist()\n",
    "\n",
    "        for j, triple_id in enumerate(top_K_triple_IDs):\n",
    "            top_K_triples.append((\n",
    "                entity_list[h_id_tensor[triple_id].item()],\n",
    "                relation_list[r_id_tensor[triple_id].item()],\n",
    "                entity_list[t_id_tensor[triple_id].item()],\n",
    "                top_K_scores[j]\n",
    "            ))\n",
    "\n",
    "        target_relevant_triple_ids = raw_sample['target_triple_probs'].nonzero().reshape(-1).tolist()\n",
    "        for triple_id in target_relevant_triple_ids:\n",
    "            target_relevant_triples.append((\n",
    "                entity_list[h_id_tensor[triple_id].item()],\n",
    "                relation_list[r_id_tensor[triple_id].item()],\n",
    "                entity_list[t_id_tensor[triple_id].item()],\n",
    "            ))\n",
    "\n",
    "    sample_dict = {\n",
    "        'question': raw_sample['question'],\n",
    "        'scored_triplets': top_K_triples,\n",
    "        'q_entity': raw_sample['q_entity'],\n",
    "        'q_entity_in_graph': [entity_list[e_id] for e_id in raw_sample['q_entity_id_list']],\n",
    "        'a_entity': raw_sample['a_entity'],\n",
    "        'a_entity_in_graph': [entity_list[e_id] for e_id in raw_sample['a_entity_id_list']],\n",
    "        'max_path_length': raw_sample['max_path_length'],\n",
    "        'target_relevant_triples': target_relevant_triples\n",
    "    }\n",
    "\n",
    "    pred_dict[raw_sample['id']] = sample_dict\n",
    "    \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a15418-bddc-46c3-a6f2-ac5c0b989846",
   "metadata": {},
   "source": [
    "COMBINED EMBEDDING + RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f9c3fe-db11-49b5-b646-3df7473db4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.emb import customEmbInferDataset\n",
    "from src.dataset.retriever import customRetrieverDataset\n",
    "\n",
    "def raw_to_pre_pred(sample, dataset_name,k):\n",
    "    \n",
    "    entity_identifier_file = f\"/home/gridsan/mhadjiivanov/meng/SubgraphRAG/retrieve/data_files/{dataset_name}/entity_identifiers.txt\"\n",
    "    entity_identifiers = []\n",
    "    with open(entity_identifier_file, 'r') as f:\n",
    "        for line in f:\n",
    "            entity_identifiers.append(line.strip())\n",
    "    entity_identifiers = set(entity_identifiers)\n",
    "    \n",
    "    sample = customEmbInferDataset(\n",
    "            sample,\n",
    "            entity_identifiers).processed_dict\n",
    "\n",
    "    id, emb_dict = embed_sample(sample)\n",
    "    infer_set = customRetrieverDataset(sample,emb_dict)\n",
    "    \n",
    "    return get_top_k(infer_set[0],k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d404a8-b598-40d8-9a95-cc9f73264e41",
   "metadata": {},
   "source": [
    "LLM MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aef024c7-8e5e-45d6-ab57-47d05d3b3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.prepare_prompts import get_prompts_for_data\n",
    "\n",
    "def get_defined_prompts(prompt_mode, model_name, llm_mode):\n",
    "    if 'gpt' in model_name or 'gpt' in prompt_mode:\n",
    "        if 'gptLabel' in prompt_mode:\n",
    "            from prompts import sys_prompt_gpt, cot_prompt_gpt\n",
    "            return sys_prompt_gpt, cot_prompt_gpt\n",
    "        else:\n",
    "            from prompts import icl_sys_prompt, icl_cot_prompt\n",
    "            return icl_sys_prompt, icl_cot_prompt\n",
    "    elif 'noevi' in prompt_mode:\n",
    "        from prompts import noevi_sys_prompt, noevi_cot_prompt\n",
    "        return noevi_sys_prompt, noevi_cot_prompt\n",
    "    elif 'icl' in llm_mode:\n",
    "        from prompts import icl_sys_prompt, icl_cot_prompt\n",
    "        return icl_sys_prompt, icl_cot_prompt\n",
    "    else:\n",
    "        from prompts import sys_prompt, cot_prompt\n",
    "        return sys_prompt, cot_prompt\n",
    "\n",
    "\n",
    "# sys_prompt, cot_prompt = get_defined_prompts(prompt_mode, model_name, llm_mode)\n",
    "# data = get_prompts_for_data([sample_dict],prompt_mode,sys_prompt, cot_prompt,thres = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eec55de-2e46-4e1d-98ef-92805fdfbc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import icl_user_prompt, icl_ass_prompt\n",
    "\n",
    "def get_outputs(outputs, model_name):\n",
    "    return outputs[0]['generated_text'][-1]['content']\n",
    "\n",
    "def llm_inf(llm, prompts, mode, model_name):\n",
    "    res = []\n",
    "    if 'sys' in mode:\n",
    "        conversation = [{\"role\": \"system\", \"content\": prompts['sys_query']}]\n",
    "\n",
    "    if 'icl' in mode:\n",
    "        conversation.append({\"role\": \"user\", \"content\": icl_user_prompt})\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": icl_ass_prompt})\n",
    "\n",
    "    if 'sys' in mode:\n",
    "        conversation.append({\"role\": \"user\", \"content\": prompts['user_query']})\n",
    "        \n",
    "        outputs = get_outputs(llm(text_inputs=conversation), model_name)\n",
    "        res.append(outputs)\n",
    "\n",
    "    if 'sys_cot' in mode:\n",
    "        if 'clear' in mode:\n",
    "            conversation = []\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": outputs})\n",
    "        conversation.append({\"role\": \"user\", \"content\": prompts['cot_query']})\n",
    "        \n",
    "        outputs = get_outputs(llm(text_inputs=conversation), model_name)\n",
    "        res.append(outputs)\n",
    "    elif \"dc\" in mode:\n",
    "        if 'ans:' not in res[0].lower() or \"ans: not available\" in res[0].lower() or \"ans: no information available\" in res[0].lower():\n",
    "            conversation.append({\"role\": \"user\", \"content\": prompts['cot_query']})\n",
    "            outputs = get_outputs(llm(text_inputs=conversation), model_name)\n",
    "            res[0] = outputs\n",
    "        res.append(\"\")\n",
    "    else:\n",
    "        res.append(\"\")\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "#llm_inf(llm, data[0], llm_mode, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "784c2ab9-78ca-46ad-b125-a8bc26f95ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:03<00:00, 61.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "llm_mode = \"sys_icl_dc\"\n",
    "model_name = \"/home/gridsan/mhadjiivanov/meng/SubgraphRAG/hf/models/Llama-3.2-3B-Instruct\"\n",
    "prompt_mode = \"scored_100\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "llm = pipeline(\"text-generation\", model=model_name, device=device, max_length = 2700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48895108-c77b-4262-a99d-22ffac8a1734",
   "metadata": {},
   "source": [
    "DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4485735-784f-40e9-87e4-fbfb4f2559b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# skipped samples: 0\n",
      "# relevant triples | median: 6 | mean: 6 | max: 6\n",
      "what are the three official languages of belgium\n",
      "['German Language', 'French', 'Dutch Language']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"/home/gridsan/mhadjiivanov/meng/SubgraphRAG/retrieve/data_files/webqsp/webqsp\")\n",
    "sample = dataset['test'][135]\n",
    "x = raw_to_pre_pred(sample,'webqsp',50)\n",
    "\n",
    "print(x['question'])\n",
    "print(x['a_entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0a3ab-76b5-4892-be64-d0737b4f4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_mode = \"sys_icl_dc\"\n",
    "model_name = \"/home/gridsan/mhadjiivanov/meng/SubgraphRAG/hf/models/Llama-3.2-3B-Instruct\"\n",
    "prompt_mode = \"scored_100\"\n",
    "\n",
    "sys_prompt, cot_prompt = get_defined_prompts(prompt_mode, model_name, llm_mode)\n",
    "data = get_prompts_for_data([x],prompt_mode,sys_prompt, cot_prompt,thres = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea693c2-4b44-431e-bbc0-76808ec85587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the triplets retrieved from a knowledge graph, please answer the question. Please return formatted answers as a list, each prefixed with \"ans:\".\n"
     ]
    }
   ],
   "source": [
    "print(data[0]['sys_query'])\n",
    "#'a_entity','scored_triplets','sys_query','user_query', 'all_query', 'cot_query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d5b234-6ae8-48ed-bd79-91e8d2cb488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['To find the three official languages of Belgium, we need to find the official languages of Belgium.\\n\\nFrom the triplets, we can see that the official languages of Belgium are:\\n\\n(Belgium,location.country.official_language,French)\\n(Belgium,location.country.official_language,German Language)\\n(Belgium,location.country.official_language,Dutch Language)\\n\\nTherefore, the formatted answers are:\\n\\nans: French\\nans: German Language\\nans: Dutch Language',\n",
       " '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_inf(llm, data[0], llm_mode, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34704d7-33a0-41cd-a05e-f62cf4b848c0",
   "metadata": {},
   "source": [
    "Subobjective Prompting Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dddf8dd2-5fe5-4d69-8862-ee87e646497f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#subobjective prompting\n",
    "def subobjective_prompt(question):\n",
    "    \n",
    "    if question[-1] != '?':\n",
    "        question += '?'\n",
    "\n",
    "    subobjective_prompt = \"\"\"Please break down the process of answering the question into as few subobjectives as possible based on semantic analysis.\n",
    "    Here is an example: \n",
    "    Q: Which of the countries in the Caribbean has the smallest country calling code?\n",
    "    Output: [\"What countries are in the Caribbean\", \"What is the country calling code for each Caribbean country\", \"What is the smallest country calling code of the ones found\"]\n",
    "\n",
    "    Now you need to directly output subobjectives of the following question in list format without other information or notes. Match the format of the example. Ensure output is a python list of strings.\n",
    "    Q: \"\"\"\n",
    "\n",
    "    prompt_and_question = subobjective_prompt + question\n",
    "    \n",
    "    return prompt_and_question\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \n",
    "#     \"content\": prompt_and_question}\n",
    "# ]\n",
    "\n",
    "# llm(text_inputs = messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a03dcb9-bcfd-49a2-a6f1-020006e935af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m prompt_and_question \u001b[38;5;241m=\u001b[39m subobjective_prompt(question)\n\u001b[1;32m      4\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_and_question}]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "question = sample[0]['question']\n",
    "prompt_and_question = subobjective_prompt(question)\n",
    "\n",
    "messages = [\n",
    "{\"role\": \"user\", \n",
    "\"content\": prompt_and_question}]\n",
    "\n",
    "subobjectives = split_subobjectives(get_outputs(llm(text_inputs = messages),\"\"))\n",
    "\n",
    "sample[0]['question'] = subobjectives[0]\n",
    "\n",
    "raw_to_pre_pred(sample,'webqsp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "368f7867-e1e5-4c29-a800-a6984d79d124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_subobjectives(s):\n",
    "    return s[s.find('[')+1:s.find(']')].split(', ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ba38b8-9c58-48f3-a432-503d6e3e8de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# skipped samples: 0\n",
      "# relevant triples | median: 1 | mean: 1 | max: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'when did the films starred by Veer-Zaara actors release',\n",
       " 'scored_triplets': [('Veer-Zaara',\n",
       "   'release_year',\n",
       "   '2004',\n",
       "   0.9847598671913147),\n",
       "  ('Veer-Zaara', 'has_genre', 'Romance', 0.7718797922134399),\n",
       "  ('Romance', 'release_year', '1999', 0.09057214111089706),\n",
       "  ('Romance', 'in_language', 'French', 0.0031211150344461203),\n",
       "  ('Veer-Zaara', 'written_by', 'Aditya Chopra', 0.0005846134154126048),\n",
       "  ('Veer-Zaara', 'has_genre', 'Drama', 0.0003422275185585022),\n",
       "  ('Veer-Zaara', 'directed_by', 'Yash Chopra', 0.00022799526050221175),\n",
       "  ('Veer-Zaara', 'starred_actors', 'Shah Rukh Khan', 0.0002083664876408875),\n",
       "  ('Veer-Zaara', 'starred_actors', 'Rani Mukerji', 3.497489160508849e-05),\n",
       "  ('Veer-Zaara', 'starred_actors', 'Preity Zinta', 8.108817382890265e-06),\n",
       "  ('Veer-Zaara', 'has_tags', 'romance', 4.055003046232741e-06),\n",
       "  ('Anatomy of Hell', 'release_year', '2004', 3.101737320321263e-06),\n",
       "  ('Veer-Zaara', 'has_tags', 'yash chopra', 1.8115691773346043e-06),\n",
       "  ('Romance', 'has_genre', 'Drama', 8.24168409963022e-07),\n",
       "  ('Romance', 'directed_by', 'Catherine Breillat', 3.044397942630894e-07),\n",
       "  ('Romance', 'written_by', 'Catherine Breillat', 1.8121671985227294e-07),\n",
       "  ('Salaam Namaste', 'release_year', '2005', 1.4368148981702689e-07),\n",
       "  ('Spanglish', 'release_year', '2004', 1.1562607937776193e-07),\n",
       "  ('Kal Ho Naa Ho', 'release_year', '2003', 1.0011127216102977e-07),\n",
       "  ('Dil Chahta Hai', 'release_year', '2001', 8.282247421220745e-08),\n",
       "  ('Romance', 'starred_actors', 'Rocco Siffredi', 8.236845872033882e-08),\n",
       "  ('Kabhi Haan Kabhi Naa', 'release_year', '1994', 7.522526601633217e-08),\n",
       "  ('Happy Together', 'has_genre', 'Romance', 4.9043379135582654e-08),\n",
       "  ('Millions', 'release_year', '2004', 4.28203108526759e-08),\n",
       "  ('First Daughter', 'has_genre', 'Romance', 2.8816272035214752e-08),\n",
       "  ('Dilwale Dulhania Le Jayenge',\n",
       "   'release_year',\n",
       "   '1995',\n",
       "   2.855441749716192e-08),\n",
       "  ('Main Hoon Na', 'release_year', '2004', 2.4929512676408194e-08),\n",
       "  ('Broken English', 'release_year', '2007', 2.4326393344153985e-08),\n",
       "  ('Romance', 'starred_actors', 'François Berléand', 2.3815143634919878e-08),\n",
       "  ('Road to Singapore', 'has_genre', 'Romance', 2.3419421069093005e-08),\n",
       "  ('Rab Ne Bana Di Jodi', 'release_year', '2008', 2.2186174675198345e-08),\n",
       "  ('Dil Se..', 'release_year', '1998', 2.1448730791462367e-08),\n",
       "  ('Mujhse Dosti Karoge!', 'release_year', '2002', 2.0736980133051475e-08),\n",
       "  ('Forever Young', 'has_genre', 'Romance', 2.056011005890923e-08),\n",
       "  ('Kuch Kuch Hota Hai', 'release_year', '1998', 1.8624390918375866e-08),\n",
       "  ('Swades', 'release_year', '2004', 1.8184561412226685e-08),\n",
       "  ('Miracle', 'release_year', '2004', 1.7968144305768874e-08),\n",
       "  ('Valley of Flowers', 'release_year', '2006', 1.648670533427321e-08),\n",
       "  ('In Love and War', 'has_genre', 'Romance', 1.6482868403500106e-08),\n",
       "  ('Hum Tum', 'release_year', '2004', 1.6211457065651302e-08),\n",
       "  ('Return to the Blue Lagoon',\n",
       "   'has_genre',\n",
       "   'Romance',\n",
       "   1.5798779173792354e-08),\n",
       "  ('Yuva', 'release_year', '2004', 1.537747351676444e-08),\n",
       "  ('Mohabbatein', 'release_year', '2000', 1.4660419545009518e-08),\n",
       "  ('Dhoom', 'release_year', '2004', 1.4436517759008893e-08),\n",
       "  (\"Summer of '42\", 'has_genre', 'Romance', 1.356074186276146e-08),\n",
       "  ('The Love of Siam', 'release_year', '2007', 1.322333176290158e-08),\n",
       "  ('Hotel Rwanda', 'release_year', '2004', 1.308089636609111e-08),\n",
       "  ('Where the Heart Is', 'release_year', '2000', 1.2834227902658313e-08),\n",
       "  ('You Are the Apple of My Eye',\n",
       "   'has_genre',\n",
       "   'Romance',\n",
       "   1.2664396642492193e-08),\n",
       "  ('Chori Chori Chupke Chupke',\n",
       "   'release_year',\n",
       "   '2001',\n",
       "   1.2627540790788316e-08)],\n",
       " 'q_entity': ['Veer-Zaara'],\n",
       " 'q_entity_in_graph': ['Veer-Zaara'],\n",
       " 'a_entity': ['2006',\n",
       "  '2004',\n",
       "  '2005',\n",
       "  '2007',\n",
       "  '2008',\n",
       "  '2003',\n",
       "  '1998',\n",
       "  '1994',\n",
       "  '2001',\n",
       "  '2011',\n",
       "  '2010',\n",
       "  '2002',\n",
       "  '1978'],\n",
       " 'a_entity_in_graph': ['1994',\n",
       "  '1998',\n",
       "  '2001',\n",
       "  '2002',\n",
       "  '2003',\n",
       "  '2004',\n",
       "  '2005',\n",
       "  '2006',\n",
       "  '2007',\n",
       "  '2008',\n",
       "  '2010',\n",
       "  '2011'],\n",
       " 'max_path_length': 1,\n",
       " 'target_relevant_triples': [('Veer-Zaara', 'release_year', '2004')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from single_sample import *\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"/home/gridsan/mhadjiivanov/meng/SubgraphRAG/retrieve/data_files/metaqa/metaqa\")\n",
    "sample = dataset['test'][135]\n",
    "\n",
    "\n",
    "text_encoder = init_text_encoder('metaqa')\n",
    "retriever_model = init_retriever('/home/gridsan/mhadjiivanov/meng/SubgraphRAG/retrieve/metaqa_Nov23-02:01:19/cpt.pth')\n",
    "\n",
    "\n",
    "raw_to_pre_pred(sample,text_encoder,retriever_model,'metaqa',50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f0cca-ecff-4b91-b422-565d1cc0d5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retriever",
   "language": "python",
   "name": "retriever"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
